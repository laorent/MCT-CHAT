# MCT Chat

This is a responsive, streaming chat application built with Next.js and powered by Google's Gemini model. It supports contextual conversations, image analysis, and real-time web search capabilities.

![MCT Chat Screenshot](https://picsum.photos/seed/mct-chat-app/1200/800)

## âœ¨ Features

- **Streaming Chat**: Real-time responses from the Gemini model for a fluid conversation.
- **Contextual Memory**: The chat remembers previous messages in the session for coherent, long-form conversations.
- **Image Analysis**: Upload images and ask questions about them, leveraging Gemini's multimodal capabilities.
- **Web-Powered Answers**: The model can search the web to provide answers on recent events and topics, with citations included in the response.
- **Responsive UI**: A clean and modern user interface that works seamlessly across desktop, tablet, and mobile devices.
- **Session Reset**: A "Clear Session" button to instantly reset the conversation.
- **Secure**: API keys are securely managed on the server-side and are not exposed to the client.

## ğŸš€ Getting Started

### Prerequisites

- [Node.js](https://nodejs.org/) (version 18.x or later)
- [pnpm](https://pnpm.io/installation) (or npm/yarn)
- A Google Gemini API key. You can get one from [Google AI Studio](https://aistudio.google.com/app/apikey).

### 1. Clone the repository

```bash
git clone <repository-url>
cd <repository-directory>
```

### 2. Install dependencies

```bash
pnpm install
```

### 3. Set up environment variables

Create a `.env.local` file in the root of your project and add your Gemini API key:

```
GEMINI_API_KEY="your-gemini-api-key"
```

You can also specify a different Gemini model by adding `GEMINI_MODEL` to your `.env.local` file. The default is `gemini-2.5-flash`.

### 4. Run the development server

```bash
pnpm dev
```

Open [http://localhost:9002](http://localhost:9002) in your browser to see the application.

## éƒ¨ç½² (Deployment)

This application is optimized for deployment on [Vercel](https://vercel.com/).

### Deploy with Vercel

1.  **Push to GitHub/GitLab/Bitbucket**: Push your code to a Git repository.
2.  **Import Project**: In your Vercel dashboard, import the project from your Git repository.
3.  **Configure Environment Variables**: Vercel will automatically detect that you're using Next.js. Go to the "Environment Variables" section in your project settings and add your `GEMINI_API_KEY`. It's recommended to use Vercel's secret management for this.
4.  **Deploy**: Click the "Deploy" button. Vercel will build and deploy your application. Once done, you'll get a URL to your live site.

The included `vercel.json` file configures the serverless function to have a longer execution time, which is recommended for AI applications.

## ğŸ› ï¸ Built With

- [Next.js](https://nextjs.org/) â€“ React Framework
- [Google Gemini API](https://ai.google.dev/docs/gemini_api_overview) â€“ AI Model
- [Tailwind CSS](https://tailwindcss.com/) â€“ CSS Framework
- [shadcn/ui](https://ui.shadcn.com/) â€“ UI Components
- [TypeScript](https://www.typescriptlang.org/) â€“ Language

## File Tree

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ next.config.ts
â”œâ”€â”€ package.json
â”œâ”€â”€ pnpm-lock.yaml
â”œâ”€â”€ postcss.config.js
â”œâ”€â”€ public
â”‚   â””â”€â”€ vercel.svg
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ app
â”‚   â”‚   â”œâ”€â”€ api
â”‚   â”‚   â”‚   â””â”€â”€ chat
â”‚   â”‚   â”‚       â””â”€â”€ route.ts
â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ chat
â”‚   â”‚   â”‚   â”œâ”€â”€ chat-form.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ chat-list.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ chat-message.tsx
â”‚   â”‚   â”‚   â””â”€â”€ chat.tsx
â”‚   â”‚   â””â”€â”€ ui
â”‚   â”‚       â”œâ”€â”€ ... (shadcn components)
â”‚   â”œâ”€â”€ lib
â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â””â”€â”€ utils.ts
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tailwind.config.ts
â”œâ”€â”€ tsconfig.json
â””â”€â”€ vercel.json
```
